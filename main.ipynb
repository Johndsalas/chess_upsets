{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "passive-collect",
   "metadata": {},
   "source": [
    "# Goal: Find drivers of upsets in chess games and create a model to predict upsets \n",
    "\n",
    "* Upset is defined as a player with a lower rating winning a game agenst a player with a higher rating\n",
    "* Model should make a predictions after having 'interviewed' each player as to thier intended opening as white and what defence they intend to use against a given opening as black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-stomach",
   "metadata": {},
   "source": [
    "### Initial Thoughts\n",
    "\n",
    "<br>\n",
    "\n",
    "* Going into this project I am of two minds.\n",
    "\n",
    "<br>\n",
    "\n",
    "**First**\n",
    "* Chess is a skill based game with no random elements (except assigning first move). \n",
    "* Because of this the player with the highest level of skill will win any game not determined by variation in player performance. \n",
    "* Because of this a given game will be won by the player with the highest level of skill a large majority of the time. * If this is true conditions underwhich variation in performance is the highest should result in the highest likelyhood of an upset.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Second**\n",
    "* It may also be the case that more skilled players are able to maintain consistancy better than less skilled players under conditions that would increased variation in thier performance.\n",
    "* If this is true, those conditions may make upsets less likely as the variance would have a grater effect on the the less skilled player than on the more skilled player.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Conclution**\n",
    "* Though these two schools of thought may point at differing conclutions, both seem grounded in reason and I am eager to see what the data can tell us\n",
    "\n",
    "### Initial Hypothisese About Drivers\n",
    "\n",
    "* There will be few instances of upsets, possibly leading to an imbalanced data set\n",
    "* As ratings for both players increase, the likelyhood of an upset will decrease \n",
    "* As the margin between player ratings increase the likelyhood of an upsets will decrease\n",
    "* Shorter time incraments will increase the likelyhood of an upset\n",
    "* Unranked games will have a higher likelyhood of an upset than ranked games\n",
    "* Games where the higher rated player is moving the white pieces (gaining first move advantage) will have a decreased likelyhood of of an upset\n",
    "* Some opening/defense stratagies may be more or less prone to upsets\n",
    "* openings/defences that are more popular or perfered by higher rated players may be more/less prone to upset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-insertion",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "following-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "\n",
    "import wrangle as w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-swimming",
   "metadata": {},
   "source": [
    "# Acquire\n",
    "\n",
    "* Data acquired from Kaggle at https://www.kaggle.com/datasnaek/chess\n",
    "* It contained 20,058 rows and 9 columns before cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-steering",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "\n",
    "**Data was very clean initially, I performed the following steps to insure that is was ready for exploration:**\n",
    "* Removed columns that did not contain useful information\\* \n",
    "* Renamed columns to premote readability\\*\n",
    "* Checked for nulls in the data (there were none)\n",
    "* Checked that column data types were ppropriate\n",
    "* Removed white space from values in object columns\n",
    "* There were no rows lost during preperation\n",
    "* Added Target column 'upset' indicating weather the lower rated player won the game\n",
    "* Added additional features to investigate (columns that could be calculated one row at a time)\\*\n",
    "* Split data into train, validate and test (approx. 60/20/20), stratifying on 'upset'\n",
    "* Added additional features to investigate (columns that requiered an aggregate calculation by column)\\*\n",
    "* aggregat calculations were performed on train data\n",
    "* resulting calculations were then applied to create columns in train, validate, and test data.\n",
    "\n",
    "\\* See data dictionary for full list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pressing-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquiring, cleaning, and adding pre-split features to data\n",
    "df = w.wrangle_chess_data(reprep = True)\n",
    "\n",
    "# Splitting data into train, validate, and test\n",
    "train, validate, test = w.split_my_data(df)\n",
    "\n",
    "# Adding post split features to data\n",
    "train, validate, test = w.fe_post_split(train, validate, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-paper",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-tract",
   "metadata": {},
   "source": [
    "### Examine Object Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "colonial-berkeley",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(train[col]) for col in train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "focused-monitor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0b8df9053e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# distribution of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0b8df9053e18>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# distribution of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' object is not callable"
     ]
    }
   ],
   "source": [
    "# distribution of the data\n",
    "columns = [col for col in train.columns if df[[col]].dtypes() == 'object']\n",
    "\n",
    "for col in columns:\n",
    "    \n",
    "    df[col].value_counts().plot(kind='bar', title = f\"{col} distribution\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-terrorism",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "* Resignations usually happen when mate is enevitable I see no reason to seperate the two\n",
    "* I wonder if running out of time has an effect on upsets? \n",
    "* White does have an advantage, though it is much smaller than I thought it would be, at about 10% higher number of wins than black\n",
    "* time_code, opening_code, and opening_name, have too many values to sort through at the moment and will have to be binned or pruened\n",
    "* upsets represent about 1/3 or the data, which is higher than I thought it would be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-stocks",
   "metadata": {},
   "source": [
    "### Examine Quantitative Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the data\n",
    "cols = ['turns', 'white_rating', 'black_rating']\n",
    "\n",
    "for col in cols:\n",
    "    plt.hist(df[col])\n",
    "    plt.title(col+' distripution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-catalyst",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "* Turns is slightly right skewed \n",
    "* Black and white rating distributions are pretty normally distributed and are nearly if not entierly identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.time_code.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-wagner",
   "metadata": {},
   "source": [
    "### I'm goint to try to prune the object columns by removing the values that do not have a significant represintation I an setting my trial cut off point at 50 or more occurrences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-dragon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-highway",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('games_preped.csv')\n",
    "df = pd.read_csv('games_preped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-lease",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-partnership",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distribution of the data\n",
    "columns = ['ended_as', 'winning_pieces', \n",
    "           'time_code', 'opening_code', \n",
    "           'opening_name', 'upset']\n",
    "\n",
    "for col in columns:\n",
    "    \n",
    "    df[col].value_counts().plot(kind='bar', title = f\"{col} distribution\")\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
